import streamlit as st
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import joblib
import json
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import openmeteo_requests
import requests_cache
from retry_requests import retry
import os
import gc
import requests
# THÆ¯ VIá»†N Má»šI CHO GMAIL
import smtplib 
import ssl 
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart

# ===============================================================
# 0. Cáº¤U HÃŒNH GMAIL (Sá»¬ Dá»¤NG Máº¬T KHáº¨U á»¨NG Dá»¤NG)
# ===============================================================

# HÃ m nÃ y sáº½ Ä‘Æ°á»£c gá»i bÃªn trong send_gmail_report Ä‘á»ƒ Ä‘áº£m báº£o Ä‘á»c Ä‘Æ°á»£c Secrets
def get_gmail_secrets():
    """Äá»c cáº¥u hÃ¬nh Gmail (User, Password, Receiver) tá»« Streamlit/Hugging Face Secrets."""
    # TrÃªn Hugging Face, báº¡n cáº§n cáº¥u hÃ¬nh GMAIL_USER, GMAIL_PASSWORD, RECEIVER_EMAIL
    try:
        # Náº¿u Ä‘ang cháº¡y trÃªn Streamlit/Hugging Face Spaces, dÃ¹ng st.secrets
        # Náº¿u cháº¡y local, dÃ¹ng os.environ (hoáº·c Ä‘á»c tá»« .streamlit/secrets.toml qua st.secrets)
        user = st.secrets.get("GMAIL_USER") or os.environ.get("GMAIL_USER")
        password = st.secrets.get("GMAIL_PASSWORD") or os.environ.get("GMAIL_PASSWORD")
        receiver = st.secrets.get("RECEIVER_EMAIL") or os.environ.get("RECEIVER_EMAIL")
             
        return user, password, receiver
    except Exception as e:
        # Fallback an toÃ n (chá»‰ láº¥y tá»« os.environ)
        return os.environ.get("GMAIL_USER"), os.environ.get("GMAIL_PASSWORD"), os.environ.get("RECEIVER_EMAIL")


def send_gmail_report(subject, message):
    """HÃ m gá»­i bÃ¡o cÃ¡o vá» Gmail."""
    
    sender_email, password, receiver_email = get_gmail_secrets()
    
    # 1. KIá»‚M TRA SECRETS CÃ“ ÄÆ¯á»¢C LOAD KHÃ”NG
    if not sender_email or not password or not receiver_email:
        print("âš ï¸ Cáº£nh bÃ¡o: Thiáº¿u biáº¿n mÃ´i trÆ°á»ng GMAIL. Bá» qua gá»­i bÃ¡o cÃ¡o.")
        st.toast("âš ï¸ Lá»—i: KhÃ´ng thá»ƒ gá»­i bÃ¡o cÃ¡o (Thiáº¿u Gmail Secrets).", icon="âŒ")
        return False
        
    # Cáº¥u hÃ¬nh SMTP
    smtp_server = "smtp.gmail.com"
    port = 465  # Cá»•ng SSL
    
    # Táº¡o ná»™i dung Email
    msg = MIMEMultipart("alternative")
    msg['Subject'] = subject
    msg['From'] = sender_email
    msg['To'] = receiver_email
    
    # Chuyá»ƒn Markdown sang HTML Ä‘Æ¡n giáº£n Ä‘á»ƒ hiá»ƒn thá»‹ Ä‘áº¹p hÆ¡n trong email
    html_content = f"""\
    <html>
      <body>
        <p style="font-family: monospace;">AI Smart Factory Report</p>
        <pre style="font-family: monospace;">{message}</pre>
        <p style="font-family: monospace;">Vui lÃ²ng kiá»ƒm tra á»©ng dá»¥ng Streamlit Ä‘á»ƒ xem biá»ƒu Ä‘á»“ chi tiáº¿t.</p>
      </body>
    </html>
    """
    part1 = MIMEText(html_content, "html")
    msg.attach(part1)
    
    # 2. KIá»‚M TRA VÃ€ Gá»¬I
    context = ssl.create_default_context()
    try:
        with smtplib.SMTP_SSL(smtp_server, port, context=context) as server:
            server.login(sender_email, password)
            server.sendmail(sender_email, receiver_email, msg.as_string())
            print("âœ… Gá»­i bÃ¡o cÃ¡o Gmail thÃ nh cÃ´ng!")
            st.toast(f"âœ… ÄÃ£ gá»­i bÃ¡o cÃ¡o tá»± Ä‘á»™ng Ä‘áº¿n {receiver_email}!", icon="ğŸ“§")
            return True
            
    except smtplib.SMTPAuthenticationError:
        error_msg = "âŒ Lá»—i xÃ¡c thá»±c Gmail. Vui lÃ²ng kiá»ƒm tra láº¡i GMAIL_PASSWORD (cáº§n lÃ  Máº­t kháº©u á»¨ng dá»¥ng 16 kÃ½ tá»±)."
        print(error_msg)
        st.toast(error_msg, icon="âŒ")
        return False
    except Exception as e:
        error_msg = f"âŒ Lá»—i máº¡ng/SMTP khi káº¿t ná»‘i Gmail: {e}"
        print(error_msg)
        st.toast("âŒ Lá»—i máº¡ng: KhÃ´ng thá»ƒ káº¿t ná»‘i tá»›i SMTP Server. Vui lÃ²ng kiá»ƒm tra káº¿t ná»‘i máº¡ng/VPN/Firewall.", icon="âŒ")
        return False

# ==========================================
# 1. Cáº¤U TRÃšC MODEL (GIá»® NGUYÃŠN)
# ==========================================
class LSTMPredictor(nn.Module):
    def __init__(self, n_features, hidden_dim=128):
        super(LSTMPredictor, self).__init__()
        self.lstm = nn.LSTM(
            input_size=n_features,
            hidden_size=hidden_dim,
            num_layers=3,
            batch_first=True,
            dropout=0.3
        )
        self.fc = nn.Linear(hidden_dim, n_features)

    def forward(self, x):
        out, _ = self.lstm(x)
        last_step = out[:, -1, :]
        prediction = self.fc(last_step)
        return prediction

# ==========================================
# 2. HÃ€M Xá»¬ LÃ Dá»® LIá»†U (GIá»® NGUYÃŠN)
# ==========================================
@st.cache_data(ttl=3600, show_spinner=False)
def process_and_enrich(df_input, _config):
    try:
        if 'data' in df_input.columns:
            def parse_safe(x):
                try:
                    return json.loads(str(x).replace("'", "\""))
                except:
                    return {}
            json_list = [parse_safe(x) for x in df_input['data']]
            json_df = pd.json_normalize(json_list)
            df_input = pd.concat([df_input[['DevAddr', 'time']], json_df], axis=1)
            del json_list, json_df
            gc.collect()

        df_input['time'] = pd.to_datetime(df_input['time'], format='mixed', utc=True)

        frames = []
        unique_devices = df_input['DevAddr'].unique()

        for dev in unique_devices:
            mask = df_input['DevAddr'] == dev
            df_subset = df_input.loc[mask].copy()
            found_channels = [col.split('.')[0] for col in df_subset.columns if col.endswith('.Actual')]
            if not found_channels: continue 
            ch = found_channels[0]
            cols_map = {
                f'{ch}.Actual': 'Actual', f'{ch}.Status': 'Status',
                f'{ch}.Actual2': 'Actual2', f'{ch}.RunTime': 'RunTime',
                f'{ch}.HeldTime': 'HeldTime'
            }
            available_cols = set(cols_map.keys()).intersection(df_subset.columns)
            if not available_cols: continue
            df_subset.rename(columns=cols_map, inplace=True)
            keep_cols = ['DevAddr', 'time', 'Actual', 'Status', 'Actual2', 'RunTime', 'HeldTime']
            for c in keep_cols:
                if c not in df_subset.columns: df_subset[c] = 0
            df_subset = df_subset[keep_cols]
            df_subset['Channel'] = ch 
            float_cols = ['Actual', 'Actual2', 'RunTime', 'HeldTime']
            df_subset[float_cols] = df_subset[float_cols].astype('float32')
            frames.append(df_subset)

        if not frames: return None
        df = pd.concat(frames, ignore_index=True)
        df.sort_values(by=['DevAddr', 'time'], inplace=True)
        grp = df.groupby('DevAddr')
        df['Speed'] = grp['Actual'].diff().fillna(0).astype('float32')
        df['d_RunTime'] = grp['RunTime'].diff().fillna(0).astype('float32')
        df['d_HeldTime'] = grp['HeldTime'].diff().fillna(0).astype('float32')
        df = df[(df['Speed'] >= 0) & (df['Speed'] < 50000)].copy()

        if df.empty: return df
        min_date = df['time'].min().strftime('%Y-%m-%d')
        max_date = df['time'].max().strftime('%Y-%m-%d')

        try:
            cache_session = requests_cache.CachedSession('.cache', expire_after=-1)
            retry_session = retry(cache_session, retries=3, backoff_factor=0.2)
            openmeteo = openmeteo_requests.Client(session=retry_session)
            params = {
                "latitude": 21.02, "longitude": 105.83,
                "start_date": min_date, "end_date": max_date,
                "hourly": ["temperature_2m", "relative_humidity_2m"]
            }
            responses = openmeteo.weather_api("https://archive-api.open-meteo.com/v1/archive", params=params)
            hourly = responses[0].Hourly()
            times = pd.date_range(
                start=pd.to_datetime(hourly.Time(), unit="s", utc=True),
                end=pd.to_datetime(hourly.TimeEnd(), unit="s", utc=True),
                freq=pd.Timedelta(seconds=hourly.Interval()),
                inclusive="left"
            )
            df_weather = pd.DataFrame({
                "time": times,
                "Temp": hourly.Variables(0).ValuesAsNumpy().astype('float32'),
                "Humidity": hourly.Variables(1).ValuesAsNumpy().astype('float32')
            })
            df_final = pd.merge_asof(df.sort_values('time'), df_weather, on='time', direction='backward')
            df_final[['Temp', 'Humidity']] = df_final[['Temp', 'Humidity']].ffill().bfill()
            return df_final
        except:
            df['Temp'] = 25.0
            df['Humidity'] = 70.0
            return df
    except Exception as e:
        st.error(f"Lá»—i xá»­ lÃ½ dá»¯ liá»‡u: {str(e)}")
        return None

# ==========================================
# 3. GIAO DIá»†N CHÃNH (ÄÃƒ Bá» NÃšT KIá»‚M TRA TELEGRAM)
# ==========================================
st.set_page_config(page_title="Smart Factory AI", layout="wide", page_icon="ğŸ­")
st.title("ğŸ­ Há»‡ thá»‘ng GiÃ¡m sÃ¡t NhÃ  mÃ¡y thÃ´ng minh (AI Powered)")

@st.cache_resource
def load_system_components():
    try:
        current_dir = os.path.dirname(os.path.abspath(__file__))
        config_path = os.path.join(current_dir, "model_config_v2.pkl")
        scaler_path = os.path.join(current_dir, "robust_scaler_v2.pkl")
        model_path = os.path.join(current_dir, "lstm_factory_v2.pth")

        if not os.path.exists(config_path): return None, None, None
        config = joblib.load(config_path)
        scaler = joblib.load(scaler_path)
        model = LSTMPredictor(n_features=config['n_features'], hidden_dim=config['hidden_dim'])
        model.load_state_dict(torch.load(model_path, map_location='cpu'))
        model.eval()
        quantized_model = torch.quantization.quantize_dynamic(
            model, {nn.Linear, nn.LSTM}, dtype=torch.qint8
        )
        return quantized_model, scaler, config
    except Exception as e:
        st.error(f"Lá»—i load model: {str(e)}")
        return None, None, None

model, scaler, config = load_system_components()

if not model:
    st.error("âš ï¸ **KhÃ´ng tÃ¬m tháº¥y Model!** Vui lÃ²ng kiá»ƒm tra file model, config vÃ  scaler.")
    st.info("ğŸ’¡ LÆ°u Ã½: HÃ£y cháº¯c cháº¯n báº¡n Ä‘Ã£ upload 3 file: `model_config_v2.pkl`, `robust_scaler_v2.pkl`, vÃ  `lstm_factory_v2.pth` lÃªn cÃ¹ng thÆ° má»¥c vá»›i file app.py")
    st.stop()

if 'analysis_done' not in st.session_state:
    st.session_state.analysis_done = False
    st.session_state.res = None
    st.session_state.n_err = 0
    st.session_state.selected_dev = None

st.sidebar.header("ğŸ“¥ Dá»¯ liá»‡u Ä‘áº§u vÃ o")
uploaded_file = st.sidebar.file_uploader("Chá»n file CSV dá»¯ liá»‡u mÃ¡y", type=["csv"])

if uploaded_file:
    if 'last_file' not in st.session_state or st.session_state.last_file != uploaded_file.name:
        st.session_state.analysis_done = False
        st.session_state.last_file = uploaded_file.name

    df_input = pd.read_csv(uploaded_file)
    st.sidebar.success(f"ÄÃ£ táº£i: {len(df_input):,} dÃ²ng")
    
    # ÄÃƒ Bá» NÃšT KIá»‚M TRA TELEGRAM Táº I ÄÃ‚Y

    with st.spinner("ğŸ”„ Äang chuáº©n hÃ³a dá»¯ liá»‡u..."):
        df_processed = process_and_enrich(df_input, config)

    if df_processed is not None and not df_processed.empty:
        def get_fixed_label(row):
            dev_id = row['DevAddr']
            original_ch = row['Channel']
            if dev_id == "4417930D77DA": return "4417930D77DA (KÃªnh 01)"
            elif dev_id == "AC0BFBCE8797": return "AC0BFBCE8797 (KÃªnh 02)"
            else: return f"{dev_id} (KÃªnh {original_ch})"

        df_processed['Label'] = df_processed.apply(get_fixed_label, axis=1)
        unique_devs = df_processed['Label'].unique()

        st.markdown("---")
        col1, col2 = st.columns([3, 1])
        with col1:
            selected_dev = st.selectbox("ğŸ‘‰ **Chá»n thiáº¿t bá»‹ cáº§n giÃ¡m sÃ¡t:**", unique_devs)
            if st.session_state.selected_dev != selected_dev:
                st.session_state.analysis_done = False
                st.session_state.selected_dev = selected_dev
                st.session_state.res = None

        with col2:
            st.write("")
            st.write("")
            turbo_mode = st.checkbox("âš¡ Cháº¿ Ä‘á»™ Turbo (Nhanh)", value=True)

        df_machine = df_processed[df_processed['Label'] == selected_dev].sort_values('time')

        with st.expander("ğŸ” Xem dá»¯ liá»‡u thÃ´ sau khi xá»­ lÃ½"):
            st.dataframe(df_machine.head(100))

        if len(df_machine) < config['seq_length'] + 5:
            st.warning(f"âš ï¸ Dá»¯ liá»‡u quÃ¡ ngáº¯n. Cáº§n tá»‘i thiá»ƒu {config['seq_length']} dÃ²ng.")
        else:
            # ---------------------------------------------------------
            # PHáº¦N NÃšT Báº¤M VÃ€ Xá»¬ LÃ Tá»° Äá»˜NG
            # ---------------------------------------------------------
            if st.button("ğŸš€ Báº®T Äáº¦U PHÃ‚N TÃCH", type="primary", use_container_width=True):
                try:
                    # 1. Chuáº©n bá»‹ dá»¯ liá»‡u
                    req_cols = config['features_list']
                    data_log = np.log1p(df_machine[req_cols])
                    data_vals = scaler.transform(data_log)
                    
                    seq_len = config['seq_length']
                    step_size = 10 if turbo_mode else 1
                    indexes = range(0, len(data_vals) - seq_len, step_size)
                    sequences = [data_vals[i:i+seq_len] for i in indexes]

                    if not sequences:
                        st.error("KhÃ´ng táº¡o Ä‘Æ°á»£c sequence dá»¯ liá»‡u.")
                        st.stop()

                    X_input = torch.tensor(np.array(sequences), dtype=torch.float32)
                    dataset = torch.utils.data.TensorDataset(X_input)
                    dataloader = torch.utils.data.DataLoader(dataset, batch_size=2048, shuffle=False)

                    # 2. Cháº¡y AI Model
                    all_preds = []
                    prog_bar = st.progress(0, text="ğŸ¤– AI Ä‘ang phÃ¢n tÃ­ch hÃ nh vi mÃ¡y...")
                    with torch.no_grad():
                        for i, batch in enumerate(dataloader):
                            preds = model(batch[0])
                            all_preds.append(preds.numpy())
                            prog_bar.progress(min((i+1)/len(dataloader), 1.0))
                    prog_bar.empty()

                    # 3. TÃ­nh toÃ¡n káº¿t quáº£
                    predictions = np.concatenate(all_preds, axis=0)
                    actual_indices = [i + seq_len for i in indexes]
                    actuals = data_vals[actual_indices]
                    target_idx = config.get('target_cols_idx', [0, 1, 2])
                    mae_loss = np.mean(np.abs(predictions[:, target_idx] - actuals[:, target_idx]), axis=1)

                    res = df_machine.iloc[actual_indices].copy()
                    res['Anomaly_Score'] = mae_loss.astype('float32')
                    res['Is_Anomaly'] = res['Anomaly_Score'] > config['threshold']

                    st.session_state.res = res
                    st.session_state.n_err = res['Is_Anomaly'].sum()
                    st.session_state.analysis_done = True
                    
                    # ======================================================
                    # ğŸ”¥ [AUTO SEND] Tá»° Äá»˜NG Gá»¬I GMAIL Táº I ÄÃ‚Y ğŸ”¥
                    # ======================================================
                    n_err = st.session_state.n_err
                    loss_vnd = n_err * 200000 
                    
                    if n_err > 0:
                        status_icon = "ğŸš¨"
                        status_text = "CÃ“ Váº¤N Äá»€"
                    else:
                        status_icon = "âœ…"
                        status_text = "á»”N Äá»ŠNH"

                    # Táº¡o ná»™i dung bÃ¡o cÃ¡o (Markdown)
                    report_msg = (
                        f"{status_icon} **BÃO CÃO Tá»° Äá»˜NG**\n"
                        f"-----------------------------\n"
                        f"ğŸ“ File: `{st.session_state.last_file}`\n"
                        f"ğŸ¤– Thiáº¿t bá»‹: `{selected_dev}`\n"
                        f"ğŸ“Š Tráº¡ng thÃ¡i: *{status_text}*\n"
                        f"âš ï¸ Sá»‘ lá»—i phÃ¡t hiá»‡n: `{n_err}`\n"
                        f"ğŸ“‰ Tá»· lá»‡ lá»—i: `{(n_err/len(res))*100:.2f}%`\n"
                        f"ğŸ’¸ Thiá»‡t háº¡i Æ°á»›c tÃ­nh: `{loss_vnd:,.0f} VND`\n"
                        f"-----------------------------\n"
                        f"ğŸ‘‰ AI vá»«a phÃ¢n tÃ­ch xong lÃºc nÃ y."
                    )
                    
                    # ThÃªm Subject cho Email
                    report_subject = f"{status_icon} BÃO CÃO AI: {status_text} | {selected_dev}"
                    
                    with st.spinner("Äang gá»­i bÃ¡o cÃ¡o vá» Gmail..."):
                        send_gmail_report(report_subject, report_msg) 
                        st.toast("ÄÃ£ tá»± Ä‘á»™ng gá»­i bÃ¡o cÃ¡o vá» Gmail!", icon="ğŸš€")
                    # ======================================================

                except Exception as e:
                    st.error(f"Lá»—i trong quÃ¡ trÃ¬nh phÃ¢n tÃ­ch: {str(e)}")

            # ---------------------------------------------------------
            # HIá»‚N THá»Š Káº¾T QUáº¢
            # ---------------------------------------------------------
            if st.session_state.analysis_done and st.session_state.res is not None:
                res = st.session_state.res
                n_err = st.session_state.n_err
                st.success(f"âœ… ÄÃ£ phÃ¢n tÃ­ch xong {len(res):,} Ä‘iá»ƒm dá»¯ liá»‡u.")

                kpi1, kpi2, kpi3 = st.columns(3)
                with kpi1:
                    if n_err == 0: st.success("### TRáº NG THÃI\n# á»”N Äá»ŠNH âœ…")
                    elif n_err < len(res) * 0.05: st.warning(f"### Cáº¢NH BÃO âš ï¸\n# {n_err} báº¥t thÆ°á»ng")
                    else: st.error(f"### NGUY HIá»‚M ğŸš¨\n# {n_err} báº¥t thÆ°á»ng")
                
                with kpi2: st.metric("Tá»· lá»‡ lá»—i", f"{(n_err/len(res))*100:.2f}%")
                with kpi3:
                    loss_vnd = n_err * 200000 
                    st.metric("Thiá»‡t háº¡i Æ°á»›c tÃ­nh", f"{loss_vnd:,.0f} Ä‘", delta="- LÃ£ng phÃ­" if n_err > 0 else "Tá»‘i Æ°u", delta_color="inverse")

                st.divider()
                st.subheader("ğŸ“Š Biá»ƒu Ä‘á»“ chi tiáº¿t")
                
                MAX_POINTS = 5000
                if len(res) > MAX_POINTS:
                    step = len(res) // MAX_POINTS
                    df_viz = res.iloc[::step]
                else:
                    df_viz = res
                df_err = res[res['Is_Anomaly']]

                fig = make_subplots(
                    rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.08,
                    subplot_titles=("Tá»‘c Ä‘á»™ mÃ¡y & Äiá»ƒm báº¥t thÆ°á»ng", "Nhiá»‡t Ä‘á»™ & Äá»™ áº©m"),
                    row_heights=[0.6, 0.4]
                )
                fig.add_trace(go.Scattergl(x=df_viz['time'], y=df_viz['Speed'], mode="lines", line=dict(color="#1f77b4", width=1.5), name="Tá»‘c Ä‘á»™"), row=1, col=1)
                if not df_err.empty:
                    fig.add_trace(go.Scattergl(x=df_err['time'], y=df_err['Speed'], mode="markers", marker=dict(color="red", size=8), name="â— Lá»—i"), row=1, col=1)
                fig.add_trace(go.Scattergl(x=df_viz['time'], y=df_viz['Temp'], mode="lines", line=dict(color="#ff7f0e", width=1.5), name="Nhiá»‡t Ä‘á»™"), row=2, col=1)
                fig.add_trace(go.Scattergl(x=df_viz['time'], y=df_viz['Humidity'], mode="lines", line=dict(color="#2ca02c", width=1.5, dash="dot"), name="Äá»™ áº©m"), row=2, col=1)
                fig.update_layout(height=700, hovermode="x unified", legend=dict(orientation="h", y=1.02))
                st.plotly_chart(fig, use_container_width=True)

                if n_err > 0:
                    with st.expander("ğŸ“‹ Xem danh sÃ¡ch lá»—i"):
                        st.dataframe(res[res["Is_Anomaly"]][["time", "Speed", "Temp", "Anomaly_Score"]].sort_values("Anomaly_Score", ascending=False), use_container_width=True)
    else:
        st.info("ğŸ‘ˆ Vui lÃ²ng upload file CSV Ä‘á»ƒ báº¯t Ä‘áº§u.")